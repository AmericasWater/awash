nyears=end_year-start_year+1
nmonths = 1
time_ind0 <- c(1:nyears*nmonths)
## Set up geographic groups
# County fips, state fips, region indexes
mastercounties <- read.csv("../../../data/global/counties.csv")
fips <- matrix(mastercounties$fips, nrow = 3109, ncol = length(time_ind0)) %>% as.vector()
time_ind <- t(matrix(time_ind0, nrow = length(time_ind0), ncol = 3109)) %>% as.vector() %>% as.factor()
state_ind <- matrix(mastercounties$state, nrow = 3109, ncol = max(time_ind0)) %>% as.vector()
region_ind <- state_ind
region_ind[which(region_ind %in% c("CT", "ME", "MA", "NH", "RI", "VT"))] <- "I"
region_ind[which(region_ind %in% c("NJ", "NY"))] <- "II"
region_ind[which(region_ind %in% c("DE", "DC", "MD", "PA", "VA", "WV"))] <- "III"
region_ind[which(region_ind %in% c("AL", "FL", "GA", "KY", "MS", "NC", "SC", "TN"))] <- "IV"
region_ind[which(region_ind %in% c("IL", "IN", "MI", "MN", "OH", "WI"))] <- "V"
region_ind[which(region_ind %in% c("AR", "LA", "NM", "OK", "TX"))] <- "VI"
region_ind[which(region_ind %in% c("IA", "KS", "MO", "NE"))] <- "VII"
region_ind[which(region_ind %in% c("CO", "MT", "ND", "SD", "UT", "WY"))] <- "VIII"
region_ind[which(region_ind %in% c("AZ", "CA", "NV"))] <- "IX"
region_ind[which(region_ind %in% c("ID", "OR", "WA"))] <- "X"
## Read-in data
# Read-in reservoir data
resdf <- read.csv("../../../data/counties/reservoirs/allreservoirs.csv")
resdf$state=state_ind[match(resdf$fips, fips[1:3109])]
# Read-in results
captures <- as.matrix(read.csv("captures.csv", header = F)) # reservoir level
max(abs(captures))
#storage <- as.matrix(read.csv("storage.csv", header = F)) # reservoir level
#smax <- matrix(as.matrix(read.csv("storagecapmax.csv", header = F)), nrow = dim(captures)[1], ncol = dim(captures)[2])#*(1-0.05)^12
failuresin <- read.csv("failuresin.csv", header = F)
failurecon <- read.csv("failurecon.csv", header = F)
# Separate captures and releases
release <- captures
release[which(release > 0)] <- 0
#proprel <- release/smax
#proprel[which(smax == 0)] <- 0
#hist(rowSums(proprel), breaks = 10)
capture <- captures
capture[which(capture < 0)] <- 0
#propcapture <- capture/smax
#propcapture[which(smax == 0)] <- 0
#hist(propcapture, breaks = 100)
#sum(rowMeans(propcapture)<0.01)/length(rowMeans(propcapture))*100
#mpctcap <- 100*rowMeans(propcapture)
## Reservoir maps
# Compute basic reservoir statistics through time
resdf$capture=apply(capture, MARGIN=1, FUN = sum)
resdf$release=apply(release, MARGIN=1, FUN = sum)
resdf$captures=apply(captures, MARGIN=1, FUN = sum)
resdf$sd_cap=apply(captures, MARGIN=1, FUN = sd)
resdf$max_capture=apply(capture, MARGIN=1, FUN = max)
resdf$max_release=-apply(release, MARGIN=1, FUN = min)
# Mas basic reservoir statistics
map <- map_data("usa")
#png(paste0(plot_path,'reservoir_map.#png'), height = 800, width = 1200)
p <- ggplot()+
geom_polygon(data=map, aes(x=long, y=lat, group = group),colour="black", fill="white")+
geom_point(data=resdf, aes(x=lon, y=lat), color='red')+
ggtitle('CONUS reservoir map')+
theme_bw()
print(p)
View(captures)
View(failurecon)
apply(captures, MARGIN=2, FUN = sum)
apply(failuresin, MARGIN=2, FUN = sum)
apply(failurecon, MARGIN=2, FUN = sum)
plot(1:10, a, type=lines)
a=apply(captures, MARGIN=2, FUN = sum)
b=apply(failuresin, MARGIN=2, FUN = sum)
c=apply(failurecon, MARGIN=2, FUN = sum)
plot(1:10, a, type=lines)
plot(1:10, a, type='l')
lines(b)
lines(c)
lines(1:10,b)
lines(1:10,c)
plot(1:10, a, type='l')
lines(1:10,b)
lines(1:10,c)
b
plot(1:10, b, type='l')
lines(1:10,c)
lines(1:10,a)
plot(1:10, b, type='l')
lines(1:10,c)
lines(1:10,a)
plot(1:10, cumsum(a), type='l')
library(dplyr)
library(ggplot2)
library(ggmap)
library(maps)
library(maptools)
library(tmap)      # package for plotting
library(readxl)    # for reading Excel
library(tmaptools)
data(wrld_simpl)
result_path = paste0("C:/Users/luc/Desktop/awash/analyses/climatevariability/", "analyzereservoir_10yrs_12months/")
setwd(result_path)
plot_path = paste0(result_path, "plots/")
dir.create(plot_path, recursive = T)
## Input run parameters
start_year=2001
end_year=2010
nyears=end_year-start_year+1
nmonths = 1
time_ind0 <- c(1:nyears*nmonths)
## Set up geographic groups
# County fips, state fips, region indexes
mastercounties <- read.csv("../../../data/global/counties.csv")
fips <- matrix(mastercounties$fips, nrow = 3109, ncol = length(time_ind0)) %>% as.vector()
time_ind <- t(matrix(time_ind0, nrow = length(time_ind0), ncol = 3109)) %>% as.vector() %>% as.factor()
state_ind <- matrix(mastercounties$state, nrow = 3109, ncol = max(time_ind0)) %>% as.vector()
region_ind <- state_ind
region_ind[which(region_ind %in% c("CT", "ME", "MA", "NH", "RI", "VT"))] <- "I"
region_ind[which(region_ind %in% c("NJ", "NY"))] <- "II"
region_ind[which(region_ind %in% c("DE", "DC", "MD", "PA", "VA", "WV"))] <- "III"
region_ind[which(region_ind %in% c("AL", "FL", "GA", "KY", "MS", "NC", "SC", "TN"))] <- "IV"
region_ind[which(region_ind %in% c("IL", "IN", "MI", "MN", "OH", "WI"))] <- "V"
region_ind[which(region_ind %in% c("AR", "LA", "NM", "OK", "TX"))] <- "VI"
region_ind[which(region_ind %in% c("IA", "KS", "MO", "NE"))] <- "VII"
region_ind[which(region_ind %in% c("CO", "MT", "ND", "SD", "UT", "WY"))] <- "VIII"
region_ind[which(region_ind %in% c("AZ", "CA", "NV"))] <- "IX"
region_ind[which(region_ind %in% c("ID", "OR", "WA"))] <- "X"
## Read-in data
# Read-in reservoir data
resdf <- read.csv("../../../data/counties/reservoirs/allreservoirs.csv")
resdf$state=state_ind[match(resdf$fips, fips[1:3109])]
# Read-in results
captures <- as.matrix(read.csv("captures.csv", header = F)) # reservoir level
max(abs(captures))
#storage <- as.matrix(read.csv("storage.csv", header = F)) # reservoir level
#smax <- matrix(as.matrix(read.csv("storagecapmax.csv", header = F)), nrow = dim(captures)[1], ncol = dim(captures)[2])#*(1-0.05)^12
failuresin <- read.csv("failuresin.csv", header = F)
failurecon <- read.csv("failurecon.csv", header = F)
# Separate captures and releases
release <- captures
release[which(release > 0)] <- 0
#proprel <- release/smax
#proprel[which(smax == 0)] <- 0
#hist(rowSums(proprel), breaks = 10)
capture <- captures
capture[which(capture < 0)] <- 0
#propcapture <- capture/smax
#propcapture[which(smax == 0)] <- 0
#hist(propcapture, breaks = 100)
#sum(rowMeans(propcapture)<0.01)/length(rowMeans(propcapture))*100
#mpctcap <- 100*rowMeans(propcapture)
a=apply(captures, MARGIN=2, FUN = sum)
b=apply(failuresin, MARGIN=2, FUN = sum)
c=apply(failurecon, MARGIN=2, FUN = sum)
plot(1:10, b, type='l')
lines(1:10,c)
lines(1:10,a)
plot(1:10, cumsum(a), type='l')
library(dplyr)
library(ggplot2)
library(ggmap)
library(maps)
library(maptools)
library(tmap)      # package for plotting
library(readxl)    # for reading Excel
library(tmaptools)
data(wrld_simpl)
result_path = paste0("C:/Users/luc/Desktop/awash/analyses/climatevariability/", "paleo_10yrs_12months/")
setwd(result_path)
plot_path = paste0(result_path, "plots/")
dir.create(plot_path, recursive = T)
## Input run parameters
start_year=2001
end_year=2010
nyears=end_year-start_year+1
nmonths = 1
time_ind0 <- c(1:nyears*nmonths)
captures <- as.matrix(read.csv("captures.csv", header = F)) # reservoir level
max(abs(captures))
failuresin <- read.csv("failuresin.csv", header = F)
failurecon <- read.csv("failurecon.csv", header = F)
# Separate captures and releases
release <- captures
release[which(release > 0)] <- 0
#proprel <- release/smax
#proprel[which(smax == 0)] <- 0
#hist(rowSums(proprel), breaks = 10)
capture <- captures
capture[which(capture < 0)] <- 0
A
a=apply(captures, MARGIN=2, FUN = sum)
b=apply(failuresin, MARGIN=2, FUN = sum)
c=apply(failurecon, MARGIN=2, FUN = sum)
plot(1:10, b, type='l')
lines(1:10,c)
lines(1:10,a)
plot(1:10, cumsum(a), type='l')
df=data.frame(Time=rep(c(start_year:end_year),2), captures=c(a1, a2), faluresin=c(b1, b2), failurescon=c(c1, c2),
type=c(rep('XXth', 10), rep('paleo', 10)))
library(dplyr)
library(ggplot2)
library(ggmap)
library(maps)
library(maptools)
library(tmap)      # package for plotting
library(readxl)    # for reading Excel
library(tmaptools)
data(wrld_simpl)
result_path = paste0("C:/Users/luc/Desktop/awash/analyses/climatevariability/", "analyzereservoir_10yrs_12months/")
setwd(result_path)
## Input run parameters
start_year=2001
end_year=2010
nyears=end_year-start_year+1
nmonths = 1
time_ind0 <- c(1:nyears*nmonths)
captures <- as.matrix(read.csv("captures.csv", header = F)) # reservoir level
max(abs(captures))
failuresin <- read.csv("failuresin.csv", header = F)
failurecon <- read.csv("failurecon.csv", header = F)
a1=apply(captures, MARGIN=2, FUN = sum)
b1=apply(failuresin, MARGIN=2, FUN = sum)
c1=apply(failurecon, MARGIN=2, FUN = sum)
result_path = paste0("C:/Users/luc/Desktop/awash/analyses/climatevariability/", "paleo_10yrs_12months/")
setwd(result_path)
## Input run parameters
start_year=2001
end_year=2010
nyears=end_year-start_year+1
nmonths = 1
time_ind0 <- c(1:nyears*nmonths)
captures <- as.matrix(read.csv("captures.csv", header = F)) # reservoir level
max(abs(captures))
failuresin <- read.csv("failuresin.csv", header = F)
failurecon <- read.csv("failurecon.csv", header = F)
a2=apply(captures, MARGIN=2, FUN = sum)
b2=apply(failuresin, MARGIN=2, FUN = sum)
c2=apply(failurecon, MARGIN=2, FUN = sum)
df=data.frame(Time=rep(c(start_year:end_year),2), captures=c(a1, a2), faluresin=c(b1, b2), failurescon=c(c1, c2),
type=c(rep('XXth', 10), rep('paleo', 10)))
View(df)
p<-ggplot(data=df, aes(x=Time))+
geom_line(aes(y=captures, color='type'))
p
p<-ggplot(data=df, aes(x=Time))+
geom_line(aes(y=captures, color=type))
p
df=data.frame(Time=rep(c(start_year:end_year),2), captures=c(a1, a2), failuresin=c(b1, b2), failurescon=c(c1, c2),
type=c(rep('XXth', 10), rep('paleo', 10)))
p<-ggplot(data=df, aes(x=Time))+
geom_line(aes(y=captures, color=type))
p
p<-ggplot(data=df, aes(x=Time))+
geom_line(aes(y=failuresin, color=type))+
geom_line(aes(y=failurescon, color=type))+
p
p<-ggplot(data=df, aes(x=Time))+
geom_line(aes(y=failuresin, color=type))+
geom_line(aes(y=failurescon, color=type))
p
df=data.frame(Time=rep(c(start_year:end_year),2), captures=c(a1, a2), failuresin=c(b1, b2), failurescon=c(c1, c2),
type=c(rep('XXth', 10), rep('paleo', 10)))
df$diff=df$failurescon-df$failuresin
p<-ggplot(data=df, aes(x=Time))+
geom_line(aes(y=captures, color=type))+
geom_line(aes(y=diff, color=type))
p
df=data.frame(Time=rep(c(start_year:end_year),2), captures=c(a1, a2), failuresin=c(b1, b2), failurescon=c(c1, c2),
type=c(rep('XXth', 10), rep('paleo', 10)))
df$diff=df$failuresin-df$failurescon
p<-ggplot(data=df, aes(x=Time))+
geom_line(aes(y=captures, color=type))+
geom_line(aes(y=diff, color=type))
p
p<-ggplot(data=df, aes(x=Time))+
geom_line(aes(y=failuresin, color=type))
p
p<-ggplot(data=df, aes(x=Time))+
geom_line(aes(y=failuresin, color=type))+
geom_line(aes(y=failurescon, color=type))
p
library(copula)
library(nor1mix)
library(lattice)
library(car)
library(locfit)
library(entropy)
library(e1071)
source("subroutines2.R")
n = 100
u <- rCopula(n, normalCopula(0.95, dim = 4))
x1 <- qnorm(u[,1],0,1)                                    # Normal Distribution
x2 <- qlnorm(u[,2],0,1)                                   # Lognormal Distribution
x3 <- qbeta(u[,3],2,5)                                    # Beta Distribution
x4 <- qnorMix(u[,4], norMix(mu = c(0,3),w = c(0.5,0.5)))  # Mixture Normal Distribution
x = cbind(x1,x2,x3,x4)
xnew1 <- rnorm(n,0,1)                                    # Normal Distribution
xnew2 <- rlnorm(n,0,1)                                   # Lognormal Distribution
xnew3 <- rbeta(n,2,5)                                    # Beta Distribution
xnew4 <- rnorMix(n, norMix(mu = c(0,3),w = c(0.5,0.5)))  # Mixture Normal Distribution
xnew = cbind(xnew1,xnew2,xnew3,xnew4)
## Simulation parameters
nboot =10000
## Run simulation
y_case1 <- fuzzy.spatsim(x, xnew, nboot=nboot, lb=NULL, ub=NULL)
## Store data for plotting results
nvar = ncol(x)
y=y_case1$yn
nsim = nrow(y)/nrow(x)
## Store simulations in 3D array w, in which: D1: "time" ie, observations per site,
## D2: "space", ie site,
## D3: simulation index
w=array(y, c(nrow(x),nvar,nsim))
for(j in 1:nvar){
w[,j,]=array(y[,j],c(nrow(x),nsim))
}
library(copula)
library(nor1mix)
library(lattice)
library(car)
library(locfit)
library(entropy)
library(e1071)
source("subroutines2.R")
n = 100
u <- rCopula(n, normalCopula(0.95, dim = 4))
x1 <- qnorm(u[,1],0,1)                                    # Normal Distribution
x2 <- qlnorm(u[,2],0,1)                                   # Lognormal Distribution
x3 <- qbeta(u[,3],2,5)                                    # Beta Distribution
x4 <- qnorMix(u[,4], norMix(mu = c(0,3),w = c(0.5,0.5)))  # Mixture Normal Distribution
x = cbind(x1,x2,x3,x4)
xnew1 <- rnorm(n,0,1)                                    # Normal Distribution
xnew2 <- rlnorm(n,0,1)                                   # Lognormal Distribution
xnew3 <- rbeta(n,2,5)                                    # Beta Distribution
xnew4 <- rnorMix(n, norMix(mu = c(0,3),w = c(0.5,0.5)))  # Mixture Normal Distribution
xnew = cbind(xnew1,xnew2,xnew3,xnew4)
## Simulation parameters
nboot =10000
## Run simulation
y_case1 <- fuzzy.spatsim(x, xnew, nboot=nboot, lb=NULL, ub=NULL)
## Store data for plotting results
nvar = ncol(x)
y=y_case1$yn
nsim = nrow(y)/nrow(x)
## Store simulations in 3D array w, in which: D1: "time" ie, observations per site,
## D2: "space", ie site,
## D3: simulation index
w=array(y, c(nrow(x),nvar,nsim))
for(j in 1:nvar){
w[,j,]=array(y[,j],c(nrow(x),nsim))
}
mean.x = apply(x,2,mean)
mean.xnew = apply(xnew,2,mean)
sd.x = apply(x,2,sd)
sd.xnew = apply(xnew,2,sd)
skew.x = apply(x,2,skewness)
skew.xnew = apply(xnew,2,skewness)
kendall = round(cor(x, use = "everything", method = "kendall"),2)
pearson = round(cor(x, use = "everything", method = "pearson"),2)
spearman = round(cor(x, use = "everything", method = "spearman"),2)
kendall.xnew = round(cor(xnew, use = "everything", method = "kendall"),2)
pearson.xnew = round(cor(xnew, use = "everything", method = "pearson"),2)
spearman.xnew = round(cor(xnew, use = "everything", method = "spearman"),2)
l=90
tdc.xx_right = matrix(0, nrow=nvar, ncol=nvar)
for(i in 1:nvar){
for (j in 1:nvar){
tdc.xx_right[i,j]=tdc.xx_right[j,i]=tdc_2_right(x[,i], x[,j], l)
}
}
newtdc.xx_right = matrix(0, nrow=nvar, ncol=nvar)
for(i in 1:ncol(x)){
for (j in 1:ncol(x)){
newtdc.xx_right[i,j]=newtdc.xx_right[j,i]=tdc_2_right(xnew[,i], xnew[,j], l)
}
}
kendall.tau = array(NA,c(nvar,nvar,nsim))
spearman.tau = array(NA,c(nvar,nvar,nsim))
pearson.tau = array(NA,c(nvar,nvar,nsim))
mean.sim = array(NA,c(nvar,nsim))
sd.sim = array(NA,c(nvar,nsim))
skew.sim = array(NA,c(nvar,nsim))
tdc.c_right = array(NA,c(nvar,nvar,nsim))
ce = 1.1
par(mfrow=c(nvar,nvar))
for (k in 1:nsim){
dum = w[,,k]
kendall.tau[,,k] = round(cor(dum, use = "everything", method = "kendall"),4)
spearman.tau[,,k] = round(cor(dum, use = "everything", method = "spearman"),4)
pearson.tau[,,k] = round(cor(dum, use = "everything", method = "pearson"),4)
for(i in 1:(nvar-1)){
for(j in i:nvar){
tdc.c_right[i,j,k]=tdc_2_right(w[,i,k],w[,j,k],l)
}
}
mean.sim[,k] = apply(dum,2,mean)
sd.sim[,k] = apply(dum,2,sd)
skew.sim[,k] = apply(dum,2,skewness)
}
## Plots in sequence
ps = 0.75
a = 0.4
xticks=paste0("w", c(1:nvar))
# Fig. 6
for(i in 1:nvar){
plot(logspline(xnew[,i]),xlab=xticks[i],ylab="density",col="white",ylim=c(0,1),cex.lab = 1.5,
cex.axis = 1.5,font.lab=2.5,family="serif",font.axis=2)
for (k in 1:nsim){
lines(locfit(~w[,j,k]),col="grey")
}
lines(locfit(~xnew[,i]),lty=2,lwd=2)
lines(locfit(~x[,i]),col="red")
}
for(i in 1:(nvar-1)){
for(j in (i+1):nvar){
plot(w[,i,],w[,j,],col="grey",xlab=xticks[i],pch=16,ylab=xticks[j],cex.lab = 1.5,
cex.axis = 1.5,font.lab=2.5,family="serif",font.axis=2)
points(xnew[,i],xnew[,j],cex=ps);
points(x[,i],x[,j],col="red",cex=ps)
lines(lowess(x[,i],x[,j]),col="red")
}
}
boxplot(t(mean.sim), ylab = "Mean",outline=FALSE,axes=FALSE,family="serif") ;
axis(1,at=c(1:nvar),xticks,family="serif",font.lab=2.5,cex.lab=1.5,cex.axis=ce)
axis(2,family="serif", ,font.lab=2.5,cex.lab=1.5,cex.axis=ce); box()
points(mean.x,pch=16,col="red")
boxplot(t(sd.sim), ylab = "SD",outline=FALSE,axes=FALSE,family="serif") ;
axis(1,at=c(1:nvar),xticks,family="serif",font.lab=2.5,cex.lab=1.5,cex.axis=ce)
axis(2,family="serif", ,font.lab=2.5,cex.lab=1.5,cex.axis=ce); box()
points(sd.x,pch=16,col="red")
boxplot(t(skew.sim), ylab = "Skewness",outline=FALSE,axes=FALSE,family="serif") ;
axis(1,at=c(1:nvar),xticks,family="serif",font.lab=2.5,cex.lab=1.5,cex.axis=ce)
axis(2,family="serif", ,font.lab=2.5,cex.lab=1.5,cex.axis=ce); box()
points(skew.x,pch=16,col="red")
# Fig. 7
ce = 1.1
xticks=c("Kendall","Spearman","Pearson")
for(i in 1:(nvar-1)){
for(j in (i+1):nvar){
boxplot(cbind(kendall.tau[i,j,],spearman.tau[i,j,],pearson.tau[i,j,]),ylim = c(-0.2,1),
ylab = "Correlation Coefficient",main=paste0("w",i, "- w", j),outline=FALSE,axes=FALSE,family="serif") ;
axis(1,at=1:3,xticks,family="serif",font.lab=2.5,cex.lab=1.5,cex.axis=ce)
axis(2,at=seq(-0.2,1,by=0.3),family="serif", ,font.lab=2.5,cex.lab=1.5,cex.axis=ce); box()
points(c(kendall.xnew[i,j],spearman.xnew[i,j],pearson.xnew[i,j]),cex=2) ;
points(c(kendall[i,j],spearman[i,j],pearson[i,j]),pch=16,cex=2,col="red") ;
}
}
for(i in 1:(nvar-1)){
for(j in (i+1):nvar){
boxplot((tdc.c_right[i,j,]),ylim=c(0,1), ylab = "lambda",main=paste0("w",i, "- w", j), j,outline=FALSE,axes=FALSE)
axis(2,at=seq(0,1,by=0.25),family="serif", ,font.lab=2,cex.lab=1.5,cex.axis=ce); box()
points(newtdc.xx_right[i,j],cex=2); points(tdc.xx_right[i,j],cex=2,pch=16,col="red")
}
}
plot(locfit(~x[,i]),col="red")
lines(locfit(~xnew[,i]),lty=2,lwd=2)
# Fig. 6
for(i in 1:nvar){
plot(logspline(xnew[,i]),xlab=xticks[i],ylab="density",col="white",ylim=c(0,1),cex.lab = 1.5,
cex.axis = 1.5,font.lab=2.5,family="serif",font.axis=2)
for (k in 1:nsim){
lines(locfit(~w[,i,k]),col="grey")
}
lines(locfit(~xnew[,i]),lty=2,lwd=2)
lines(locfit(~x[,i]),col="red")
}
library(dplyr)
library(ggplot2)
library(ggmap)
library(maps)
library(maptools)
library(tmap)      # package for plotting
library(readxl)    # for reading Excel
library(tmaptools)
data(wrld_simpl)
result_path = paste0("C:/Users/luc/Desktop/awash/analyses/climatevariability/", "analyzereservoir_10yrs_12months/")
setwd(result_path)
## Input run parameters
start_year=2001
end_year=2010
nyears=end_year-start_year+1
nmonths = 1
time_ind0 <- c(1:nyears*nmonths)
captures <- as.matrix(read.csv("captures.csv", header = F)) # reservoir level
max(abs(captures))
failuresin <- read.csv("failuresin.csv", header = F)
a1=apply(captures, MARGIN=2, FUN = sum)
failurecon <- read.csv("failurecon.csv", header = F)
b1=apply(failuresin, MARGIN=2, FUN = sum)
c1=apply(failurecon, MARGIN=2, FUN = sum)
result_path = paste0("C:/Users/luc/Desktop/awash/analyses/climatevariability/", "paleo_10yrs_12months/")
setwd(result_path)
## Input run parameters
start_year=2001
end_year=2010
nyears=end_year-start_year+1
nmonths = 1
time_ind0 <- c(1:nyears*nmonths)
captures <- as.matrix(read.csv("captures.csv", header = F)) # reservoir level
max(abs(captures))
failuresin <- read.csv("failuresin.csv", header = F)
failurecon <- read.csv("failurecon.csv", header = F)
a2=apply(captures, MARGIN=2, FUN = sum)
b2=apply(failuresin, MARGIN=2, FUN = sum)
c2=apply(failurecon, MARGIN=2, FUN = sum)
df=data.frame(Time=rep(c(start_year:end_year),2), captures=c(a1, a2), failuresin=c(b1, b2), failurescon=c(c1, c2),
type=c(rep('XXth', 10), rep('paleo', 10)))
df$diff=df$failuresin-df$failurescon
p<-ggplot(data=df, aes(x=Time))+
geom_line(aes(y=captures, color=type))+
geom_line(aes(y=diff, color=type))
p
p<-ggplot(data=df, aes(x=Time))+
geom_line(aes(y=failuresin, color=type))+
geom_line(aes(y=failurescon, color=type))
p
