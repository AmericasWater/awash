data {
# Number of data points
int n1;
int n2;
# Milk production
int y1[n1];
int y2[n2];
}
parameters {
real<lower=0> lambda1;
real<lower=0> lambda2;
}
model {
lambda1 ~ uniform(0, 10);
lambda2 ~ uniform(0, 10);
y1 ~ poisson(lambda1);
y2 ~ poisson(lambda2);
}
generated quantities {
}
"
diet_eggs <- c(6, 4, 2, 3, 4, 3, 0, 4, 0, 6, 3)
normal_eggs <- c(4, 2, 1, 1, 2, 1, 2, 1, 3, 2, 1)
data_list <- list(y1 = diet_eggs, y2 = normal_eggs, n1 = length(diet_eggs), n2 = length(normal_eggs))
# Compiling and producing posterior samples from the model.
stan_samples <- stan(model_code = model_string, data = data_list)
# Plotting and summarizing the posterior distribution
stan_samples
plot(stan_samples)
s <- as.data.frame(stan_samples)
head(s)
# The probability that the diet makes chicken produce more eggs on average
lambda_diff = s$lambda1 - s$lambda2
mean(mu_diff > 0)
# Plotting distribution of the difference between theta1 and theta2
hist(s$mu2 - s$mu1)
# The probability that the diet makes chicken produce more eggs on average
lambda_diff = s$lambda1 - s$lambda2
mean(lambda_diff > 0)
# Plotting distribution of the difference between theta1 and theta2
hist(lambda_diff)
d <- data.frame(
milk = c(651, 679, 374, 601, 401, 609, 767, 709, 704, 679, 798, 1139,
529, 609, 553, 743, 151, 544, 488, 555, 257, 692, 678, 675, 538),
group = c(1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2,
2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2))
data_list <- list(y = d$milk, x = d$group, n = length(d$milk),
n_groups = max(d$group))
d <- data.frame(
milk = c(651, 679, 374, 601, 401, 609, 767, 709, 704, 679, 798, 1139,
529, 609, 553, 743, 151, 544, 488, 555, 257, 692, 678, 675, 538),
group = c(1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2,
2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2))
data_list1 <- list(y = d$milk, x = d$group, n = length(d$milk),
n_groups = max(d$group))
diet_milk <- c(651, 679, 374, 601, 401, 609, 767, 709, 704, 679)
normal_milk <- c(798, 1139, 529, 609, 553, 743, 151, 544, 488, 555, 257, 692, 678, 675, 538)
data_list <- list(y1 = diet_milk, y2 = normal_milk, n1 = length(diet_milk), n2 = length(normal_milk))
# Compiling and producing posterior samples from the model.
stan_samples <- stan(model_code = model_string, data = data_list)
model_string <- "
data {
# Number of data points
int n;
# Number of groups
int n_groups;
# Milk production
vector[n] y;
}
parameters {
vector[n_groups] mu;
vector[n_groups] sigma;
}
model {
mu ~ uniform(0, 2000);
sigma ~ uniform(0, 1000);
#for(i in 1:n) {
#  y[i] ~ normal( mu[x[i]], sigma[x[i]] )
#}
y ~ normal( mu[x], sigma[x] );
}
generated quantities {
}
"
d <- data.frame(
milk = c(651, 679, 374, 601, 401, 609, 767, 709, 704, 679, 798, 1139, 529,
609, 553, 743, 151, 544, 488, 555, 257, 692, 678, 675, 538, 1061,
721, 595, 784, 877, 562, 800, 684, 741, 516),
group = c(1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3))
data_list <- list(y = d$milk, x = d$group, n = length(d$milk),
n_groups = max(d$group))
# Compiling and producing posterior samples from the model.
stan_samples <- stan(model_code = model_string, data = data_list)
model_string <- "
data {
# Number of data points
int n;
# Number of groups
int n_groups;
# Mapping observations to group
int x[n];
# Milk production
vector[n] y;
}
parameters {
vector[n_groups] mu;
vector[n_groups] sigma;
}
model {
mu ~ uniform(0, 2000);
sigma ~ uniform(0, 1000);
#for(i in 1:n) {
#  y[i] ~ normal( mu[x[i]], sigma[x[i]] )
#}
y ~ normal( mu[x], sigma[x] );
}
generated quantities {
}
"
# Compiling and producing posterior samples from the model.
stan_samples <- stan(model_code = model_string, data = data_list)
# Plotting and summarizing the posterior distribution
stan_samples
plot(stan_samples)
model_string <- "
data {
# Number of data points
int n;
# Number of groups
int n_groups;
# Mapping observations to group
int x[n];
# Milk production
vector[n] y;
}
parameters {
vector[n_groups] mu;
vector<lower=0>[n_groups] sigma;
}
model {
mu ~ uniform(0, 2000);
sigma ~ uniform(0, 1000);
#for(i in 1:n) {
#  y[i] ~ normal( mu[x[i]], sigma[x[i]] )
#}
y ~ normal( mu[x], sigma[x] );
}
generated quantities {
}
"
d <- data.frame(
milk = c(651, 679, 374, 601, 401, 609, 767, 709, 704, 679, 798, 1139, 529,
609, 553, 743, 151, 544, 488, 555, 257, 692, 678, 675, 538, 1061,
721, 595, 784, 877, 562, 800, 684, 741, 516),
group = c(1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3))
data_list <- list(y = d$milk, x = d$group, n = length(d$milk),
n_groups = max(d$group))
# Compiling and producing posterior samples from the model.
stan_samples <- stan(model_code = model_string, data = data_list)
# Plotting and summarizing the posterior distribution
stan_samples
plot(stan_samples)
s <- as.data.frame(stan_samples)
head(s)
# The probability that the diet makes cows produce more milk on average
mu_diff31 = s$mu[3] - s$mu[1]
mu_diff32 = s$mu[3] - s$mu[2]
mean(mu_diff31)
mean(mu_diff32)
# The probability that the diet makes cows produce more milk on average
mu_diff31 = s$mu[3] - s$mu[1]
mu_diff32 = s$mu[3] - s$mu[2]
mean(mu_diff31, na.rm=T)
mean(mu_diff32, na.rm=T)
s$mu[3]
s
# The probability that the diet makes cows produce more milk on average
mu_diff31 = s$`mu[3]` - s$`mu[1]`
mu_diff32 = s$`mu[3]` - s$`mu[2]`
mean(mu_diff31, na.rm=T)
mean(mu_diff32, na.rm=T)
d <- data.frame(milk = c(685, 691, 476, 1151, 879, 725, 1190, 1107, 809, 539,
298, 805, 820, 498, 1026, 1217, 1177, 684, 1061, 834),
hours = c(3, 7, 6, 10, 6, 5, 10, 11, 9, 3, 6, 6, 3, 5, 8, 11,
12, 9, 5, 5))
data_list <- list(y = d$milk, h = d$hours, n = length(d$milk))
model_string <- "
data {
# Number of data points
int n;
# Milk production
vector[n] y;
# Sunshine hours
vector[n] h;
}
parameters {
real mu;
real beta;
vector<lower=0>[n_groups] sigma;
}
model {
mu ~ uniform(0, 2000);
beta ~ uniform(0, 2000);
sigma ~ uniform(0, 1000);
y ~ normal( mu+h*beta, sigma );
}
generated quantities {
}
"
# Compiling and producing posterior samples from the model.
stan_samples <- stan(model_code = model_string, data = data_list)
model_string <- "
data {
# Number of data points
int n;
# Milk production
vector[n] y;
# Sunshine hours
vector[n] h;
}
parameters {
real mu;
real beta;
real<lower=0> sigma;
}
model {
mu ~ uniform(0, 2000);
beta ~ uniform(0, 2000);
sigma ~ uniform(0, 1000);
y ~ normal( mu+h*beta, sigma );
}
generated quantities {
}
"
# Compiling and producing posterior samples from the model.
stan_samples <- stan(model_code = model_string, data = data_list)
# Plotting and summarizing the posterior distribution
stan_samples
plot(stan_samples)
s <- as.data.frame(stan_samples)
head(s)
plot(d$hours, d$milk, xlim=c(0, 13), ylim = c(0, 1300))
# Adding a sample of the posterior draws to the plot in order to visualize the
# uncertainty of the regression line.
s <- as.data.frame(stan_samples)
for(i in sample(nrow(s), size = 20)) {
abline(s[i,"beta0"], s[i,"beta1"], col = "gray")
}
plot(d$hours, d$milk, xlim=c(0, 13), ylim = c(0, 1300))
# Adding a sample of the posterior draws to the plot in order to visualize the
# uncertainty of the regression line.
s <- as.data.frame(stan_samples)
for(i in sample(nrow(s), size = 20)) {
abline(s[i,"mu"], s[i,"beta"], col = "gray")
}
library(readr)
NC <- read_delim("north_carolina.tsv.gz", delim = "\t")
load(".RData")
load("NC.RData")
load(".RData")
save(list(NC=NC, stops=stops), file='NC2.RData')
save(NC, file='NC2.RData')
save(stops, file='stops.RData')
knitr::opts_chunk$set(LABEL = TRUE, cache = TRUE, results = "hide", message = FALSE, seed = 12345)
library(rstan)
library(rstanarm)
library(brms)
options(mc.cores = parallel::detectCores())
setwd('C:/Users/luc/Desktop/GR5065/HW6')
load("NC2.RData")
load("stops.RData")
library(dplyr)
NC$n_stop=1
NC %>% group_by(police_department, race) %>%
summarise(n_stops=sum(n_stop), search_conducted=sum(search_conducted), contraband_found=sum(contraband_found, na.rm=T)) -> NC2
data_list <- list(N=nrow(NC2), R=4, D=100, r=as.numeric(factor(NC2$race)), d=as.numeric(factor(NC2$police_department)), n=NC2$n_stops, s=NC2$search_conducted, h=NC2$contraband_found)
# Compiling and producing posterior samples from the model.
stan_samples <- stan(file = "north_carolina_police.stan", data = data_list, chains = 2,iter = 200, control = list(adapt_delta = 0.99, max_treedepth=20))
# Compiling and producing posterior samples from the model.
stan_samples <- stan(file = "north_carolina_police.stan", data = data_list, chains = 2,iter = 200, control = list(adapt_delta = 0.99, max_treedepth=20))
# Compiling and producing posterior samples from the model.
stan_samples <- stan(file = "north_carolina_police.stan", data = data_list, chains = 2,iter = 200, control = list(adapt_delta = 0.8, max_treedepth=10))
# Compiling and producing posterior samples from the model.
stan_samples <- stan(file = "north_carolina_police.stan", data = data_list, chains = 2,iter = 500, control = list(adapt_delta = 0.9, max_treedepth=10))
rstan:::rstudio_stanc("C:/Users/luc/Desktop/GR5065/HW6/interval_regv2.stan")
sm <- rstan::stan_model("C:/Users/luc/Desktop/GR5065/HW6/interval_regv2.stan")
sm
rstan:::rstudio_stanc("C:/Users/luc/Desktop/GR5065/Final/cigarettes_rng.stan")
rstan:::rstudio_stanc("C:/Users/luc/Desktop/GR5065/Final/cigarettes_rng.stan")
rstan:::rstudio_stanc("C:/Users/luc/Desktop/GR5065/Final/cigarettes_rng.stan")
rstan:::rstudio_stanc("C:/Users/luc/Desktop/GR5065/Final/cigarettes_rng.stan")
load('C:/Users/luc/Desktop/awash/data/counties/waternet/waternet.RData')
a=nc_open('C:/Users/luc/Desktop/awash/data/cache/counties/VIC_WB.nc')
library(ncdf4)
a=nc_open('C:/Users/luc/Desktop/awash/data/cache/counties/VIC_WB.nc')
a$var
b=ncvar_get('month')
b=ncvar_get(a, 'month')
b
/
735/12
names(a$var)
a=nc_open('C:/Users/luc/Desktop/awash/data/cache/counties/contributing_runoff_by_gage.nc')
names(a$var)
b=ncvar_get(a, 'totalflow')
b
names(a$var)
ncvar_get(a, 'gage_id')
d=ncvar_get(a, 'gage_id')
d
load('C:/Users/luc/Desktop/awash/data/cache/counties/waternet/waternet.RData')
load('C:/Users/luc/Desktop/awash/data/counties/waternet/waternet.RData')
load('C:/Users/luc/Desktop/awash/data/counties/waternet/countydraws.RData')
load('C:/Users/luc/Desktop/Paleo/LBDA_sf/SF_disagg/results/monthly.disaggregation.Rdata')
load('C:/Users/luc/Desktop/Paleo/LBDA_sf/SF_disagg/results/CONUS/monthly.disaggregation.Rdata')
data=nc_open('C:/Users/luc/Desktop/awash/data/cache/paleo/VIC_WB.nc')
library(ncdf4)
data=nc_open('C:/Users/luc/Desktop/awash/data/cache/paleo/VIC_WB.nc')
names(data$var)
t=ncvar_get(data, 'month')
t
data=nc_open('C:/Users/luc/Desktop/awash/data/cache/counties/VIC_WB.nc')
names(data$var)
t=ncvar_get(data, 'month')
t
load("C:/Users/luc/Desktop/awash/data/counties/waternet/waternet.RData")
load('C:/Users/luc/Desktop/awash/data/counties/waternet/waternet.RData')
library(ncdf4)
nc_data=nc_open("C:/Users/luc/Desktop/awash/data/cache/counties/contributing_runoff_by_gage.nc")
names(nc_data$dim)
nc_data$dim
nc_data$gage
names(nc_data$dim)
nc_data$id
names(nc_data$var)
names(nc_data$dim)
load('C:/Users/luc/Desktop/awash/data/counties/waternet/waternet.RData')
load('C:/Users/luc/Desktop/awash/data/counties/waternet/waternet.RData')
library(ncdf4)
library(ggplot2)
library(ggmap)
library(broom)
library(maps)
library(maptools)
library(dplyr)
data(wrld_simpl)
################################################################################################################
##  Pre-process data and basic analysis
################################################################################################################
NOR=subset(wrld_simpl, NAME=="Norway")
setwd('C:/Users/luc/Desktop/CAI/proj1')
station_locations = read.csv("station_locations.csv")
station_locations$ids=c("Bruvolli", "Eidset", "Ekkjestolen", "Reingardsaga", "Stokkelandsana")
p <- ggplot()+
geom_polygon(data=tidy(NOR), aes(x=long, y=lat, group=group),colour="black", fill="white")+
geom_point(data=station_locations, aes(x=lon, y=lat))+
geom_text(data=station_locations,aes(x=lon, y=lat,label=station_id),hjust=0, vjust=0)+
theme_bw()
p
station_files = list.files()
station_files = station_files[grepl(".csv", station_files)]
station_files = station_files[!grepl("station_locations", station_files)]
Bruvolli = read.csv(station_files[1])
Eidset = read.csv(station_files[2])
Ekkjestolen = read.csv(station_files[3])
Reingardsaga = read.csv(station_files[4])
Stokkelandsana = read.csv(station_files[5])
Bruvolli$Flow[Bruvolli$Flow==-9999] <- NA
Eidset$Flow[Eidset$Flow==-9999] <- NA
Ekkjestolen$Flow[Ekkjestolen$Flow==-9999] <- NA
Reingardsaga$Flow[Reingardsaga$Flow==-9999] <- NA
Stokkelandsana$Flow[Stokkelandsana$Flow==-9999] <- NA
Bruvolli$Date=as.Date(Bruvolli$Date, format="%Y.%m.%d")
Eidset$Date=as.Date(Eidset$Date, format="%Y.%m.%d")
Ekkjestolen$Date=as.Date(Ekkjestolen$Date, format="%Y.%m.%d")
Reingardsaga$Date=as.Date(Reingardsaga$Date, format="%Y.%m.%d")
Stokkelandsana$Date=as.Date(Stokkelandsana$Date, format="%Y.%m.%d")
start=min(Bruvolli$Date, Eidset$Date, Ekkjestolen$Date, Reingardsaga$Date, Stokkelandsana$Date)
end=max(Bruvolli$Date, Eidset$Date, Ekkjestolen$Date, Reingardsaga$Date, Stokkelandsana$Date)
df=data.frame(Date=seq(start, end, by=1))
df$Stokkelandsana=df$Reingardsaga=df$Ekkjestolen=df$Eidset=df$Bruvolli=NA
df$Bruvolli[match(Bruvolli$Date,df$Date)]=Bruvolli$Flow
df$Eidset[match(Eidset$Date,df$Date)]=Eidset$Flow
df$Ekkjestolen[match(Ekkjestolen$Date,df$Date)]=Ekkjestolen$Flow
df$Reingardsaga[match(Reingardsaga$Date,df$Date)]=Reingardsaga$Flow
df$Stokkelandsana[match(Stokkelandsana$Date,df$Date)]=Stokkelandsana$Flow
cor(df[,2:6], use="pairwise.complete.obs")
pairs(df[,2:6])
acf(ts(df$Bruvolli[!is.na(df$Bruvolli)]))
acf(ts(df$Eidset[!is.na(df$Eidset)]))
acf(ts(df$Ekkjestolen[!is.na(df$Ekkjestolen)]))
acf(ts(df$Reingardsaga[!is.na(df$Reingardsaga)]))
acf(ts(df$Stokkelandsana[!is.na(df$Stokkelandsana)]))
plot(df$Bruvolli)
plot(df$Eidset)
plot(df$Ekkjestolen)
plot(df$Reingardsaga)
p
library(ncdf4)
nc_data=nc_open("C:/Users/luc/Desktop/awash/data/cache/counties/contributing_runoff_by_gage.nc")
library(ncdf4)
nc_data=nc_open("C:/Users/luc/Desktop/awash/data/cache/counties/contributing_runoff_by_gage.nc")
library(PBSmapping)
library(dplyr)
library(ggplot2)
library(ggmap)
library(maps)
library(maptools)
library(tmap)      # package for plotting
library(readxl)    # for reading Excel
library(tmaptools)
require(tidyr)
require(reshape2)
data(wrld_simpl)
wd_path = paste0("C:/Users/luc/Desktop/awash/analyses/climatevariability/")
setwd(wd_path)
# load
dem=read.csv("analyzereservoir_10yrs_12months/dem_tot.csv", header=F)
dem_p=read.csv("paleo_10yrs_12months/dem_tot.csv", header=F)
dem_diff=sum(unlist(dem), na.rm=T)-sum(unlist(dem_p), na.rm=T)
failurecon <- read.csv("analyzereservoir_10yrs_12months/failurecon.csv", header = F)
failurecon_p=read.csv("paleo_10yrs_12months/failurecon.csv", header=F)
failurecon_diff=sum(unlist(failurecon), na.rm=T)-sum(unlist(failurecon_p), na.rm=T)
failure=failurecon
per_cent_failure=100*failure/dem_tot
per_cent_failure[per_cent_failure==Inf]=0
p <- ggplot()+
geom_polygon(data=map, aes(x=long, y=lat, group = group),colour="black", fill="white")
# Set-up
start_year=2001
end_year=2010
tstep_py=1
nyears=end_year-start_year+1
time_ind0 <- 1:nyears*tstep_py
dir.create('plots', showWarnings=F)
# - county fips, state fips, region indexes
mastercounties <- read.csv("../../data/global/counties.csv")
fips <- matrix(mastercounties$fips, nrow = 3109, ncol = length(time_ind0)) %>% as.vector()
time_ind <- t(matrix(time_ind0, nrow = length(time_ind0), ncol = 3109)) %>% as.vector() %>% as.factor()
state_ind <- matrix(mastercounties$state, nrow = 3109, ncol = max(time_ind0)) %>% as.vector()
region_ind <- state_ind
region_ind[which(region_ind %in% c("CT", "ME", "MA", "NH", "RI", "VT"))] <- "I"
region_ind[which(region_ind %in% c("NJ", "NY"))] <- "II"
region_ind[which(region_ind %in% c("DE", "DC", "MD", "PA", "VA", "WV"))] <- "III"
region_ind[which(region_ind %in% c("AL", "FL", "GA", "KY", "MS", "NC", "SC", "TN"))] <- "IV"
region_ind[which(region_ind %in% c("IL", "IN", "MI", "MN", "OH", "WI"))] <- "V"
region_ind[which(region_ind %in% c("AR", "LA", "NM", "OK", "TX"))] <- "VI"
region_ind[which(region_ind %in% c("IA", "KS", "MO", "NE"))] <- "VII"
region_ind[which(region_ind %in% c("CO", "MT", "ND", "SD", "UT", "WY"))] <- "VIII"
region_ind[which(region_ind %in% c("AZ", "CA", "NV"))] <- "IX"
region_ind[which(region_ind %in% c("ID", "OR", "WA"))] <- "X"
fips <- mastercounties$fips
resdf <- read.csv("../../data/counties/reservoirs/allreservoirs.csv")
shapes <- importShapefile("C:/Users/luc/Desktop/awash/data/mapping/US_county_2000-simple")
polydata <- attributes(shapes)$PolyData
polydata$STATE <- as.numeric(levels(polydata$STATE))[polydata$STATE]
polydata$COUNTY <- as.numeric(levels(polydata$COUNTY))[polydata$COUNTY]
shapes$id <- polydata$STATE[shapes$PID] * 100 + polydata$COUNTY[shapes$PID] / 10;
names(shapes) <- tolower(names(shapes));
stateshapes <- importShapefile("../../data/mapping/tl_2010_us_state00/tl_2010_us_state00-simple")
statespolydata <- attributes(stateshapes)$PolyData
stateshapes$x <- stateshapes$X
stateshapes$y <- stateshapes$Y
stateshapes$id <- stateshapes$PID
failure_means=rowMeans(failurecon)
dem_sum=rowSums(dem)
dem_p_sum=rowSums(dem_p)
df <- data.frame(fips,dem_sum,dem_p_sum)
df$storage=NA
for (i in 1:nrow(df)){
df$storage[i]=sum(resdf$MAXCAP[which(resdf$fips==df$fips[i])])
}
df$ratio=df$dem_sum/df$storage
df$ratio_p=df$dem_p_sum/df$storage
library("RColorBrewer")
myPalette <- colorRampPalette(rev(brewer.pal(11, "Spectral")))
sc <- scale_colour_gradientn(colours = myPalette(100), limits=c(0, 3))
gplot1 <- ggplot() +
geom_map(data=stateshapes, map=stateshapes, aes(map_id=PID), color='gray', fill=NA) +
geom_map(data=df, aes(fill=ratio, map_id=fips), map=shapes) +
scale_fill_gradient(low="blue", high="red")+
expand_limits(x=c(-2500000, 2500000), y=c(-1.4e6, 1.6e6)) +
theme_bw() + theme(legend.justification=c(0,0), legend.position=c(0,0)) + xlab('') + ylab('')
gplot1
gplot2 <- ggplot() +
geom_map(data=stateshapes, map=stateshapes, aes(map_id=PID), color='gray', fill=NA) +
geom_map(data=df, aes(fill=ratio_p, map_id=fips), map=shapes) +
scale_fill_gradient(low="blue", high="red")+
expand_limits(x=c(-2500000, 2500000), y=c(-1.4e6, 1.6e6)) +
theme_bw() + theme(legend.justification=c(0,0), legend.position=c(0,0)) + xlab('') + ylab('')
gplot2
gplot1
gplot1 <- ggplot() +
geom_map(data=stateshapes, map=stateshapes, aes(map_id=PID), color='gray', fill=NA) +
geom_map(data=df, aes(fill=ratio, map_id=fips), map=shapes) +
scale_fill_gradient(low="blue", high="red")+
expand_limits(x=c(-2500000, 2500000), y=c(-1.4e6, 1.6e6)) +
theme_bw() + theme(legend.justification=c(0,0), legend.position=c(0,0)) + xlab('') + ylab('')+
ggtitle("Ratio of total demand over maximum storage capacity - comtemporary case")
gplot1
gplot2 <- ggplot() +
geom_map(data=stateshapes, map=stateshapes, aes(map_id=PID), color='gray', fill=NA) +
geom_map(data=df, aes(fill=ratio_p, map_id=fips), map=shapes) +
scale_fill_gradient(low="blue", high="red")+
expand_limits(x=c(-2500000, 2500000), y=c(-1.4e6, 1.6e6)) +
theme_bw() + theme(legend.justification=c(0,0), legend.position=c(0,0)) + xlab('') + ylab('')+
ggtitle("Ratio of total demand over maximum storage capacity - paleo case")
gplot2
gplot1
gplot2
