mean(mu_diff31)
mean(mu_diff32)
# The probability that the diet makes cows produce more milk on average
mu_diff31 = s$mu[3] - s$mu[1]
mu_diff32 = s$mu[3] - s$mu[2]
mean(mu_diff31, na.rm=T)
mean(mu_diff32, na.rm=T)
s$mu[3]
s
# The probability that the diet makes cows produce more milk on average
mu_diff31 = s$`mu[3]` - s$`mu[1]`
mu_diff32 = s$`mu[3]` - s$`mu[2]`
mean(mu_diff31, na.rm=T)
mean(mu_diff32, na.rm=T)
d <- data.frame(milk = c(685, 691, 476, 1151, 879, 725, 1190, 1107, 809, 539,
298, 805, 820, 498, 1026, 1217, 1177, 684, 1061, 834),
hours = c(3, 7, 6, 10, 6, 5, 10, 11, 9, 3, 6, 6, 3, 5, 8, 11,
12, 9, 5, 5))
data_list <- list(y = d$milk, h = d$hours, n = length(d$milk))
model_string <- "
data {
# Number of data points
int n;
# Milk production
vector[n] y;
# Sunshine hours
vector[n] h;
}
parameters {
real mu;
real beta;
vector<lower=0>[n_groups] sigma;
}
model {
mu ~ uniform(0, 2000);
beta ~ uniform(0, 2000);
sigma ~ uniform(0, 1000);
y ~ normal( mu+h*beta, sigma );
}
generated quantities {
}
"
# Compiling and producing posterior samples from the model.
stan_samples <- stan(model_code = model_string, data = data_list)
model_string <- "
data {
# Number of data points
int n;
# Milk production
vector[n] y;
# Sunshine hours
vector[n] h;
}
parameters {
real mu;
real beta;
real<lower=0> sigma;
}
model {
mu ~ uniform(0, 2000);
beta ~ uniform(0, 2000);
sigma ~ uniform(0, 1000);
y ~ normal( mu+h*beta, sigma );
}
generated quantities {
}
"
# Compiling and producing posterior samples from the model.
stan_samples <- stan(model_code = model_string, data = data_list)
# Plotting and summarizing the posterior distribution
stan_samples
plot(stan_samples)
s <- as.data.frame(stan_samples)
head(s)
plot(d$hours, d$milk, xlim=c(0, 13), ylim = c(0, 1300))
# Adding a sample of the posterior draws to the plot in order to visualize the
# uncertainty of the regression line.
s <- as.data.frame(stan_samples)
for(i in sample(nrow(s), size = 20)) {
abline(s[i,"beta0"], s[i,"beta1"], col = "gray")
}
plot(d$hours, d$milk, xlim=c(0, 13), ylim = c(0, 1300))
# Adding a sample of the posterior draws to the plot in order to visualize the
# uncertainty of the regression line.
s <- as.data.frame(stan_samples)
for(i in sample(nrow(s), size = 20)) {
abline(s[i,"mu"], s[i,"beta"], col = "gray")
}
library(readr)
NC <- read_delim("north_carolina.tsv.gz", delim = "\t")
load(".RData")
load("NC.RData")
load(".RData")
save(list(NC=NC, stops=stops), file='NC2.RData')
save(NC, file='NC2.RData')
save(stops, file='stops.RData')
knitr::opts_chunk$set(LABEL = TRUE, cache = TRUE, results = "hide", message = FALSE, seed = 12345)
library(rstan)
library(rstanarm)
library(brms)
options(mc.cores = parallel::detectCores())
setwd('C:/Users/luc/Desktop/GR5065/HW6')
load("NC2.RData")
load("stops.RData")
library(dplyr)
NC$n_stop=1
NC %>% group_by(police_department, race) %>%
summarise(n_stops=sum(n_stop), search_conducted=sum(search_conducted), contraband_found=sum(contraband_found, na.rm=T)) -> NC2
data_list <- list(N=nrow(NC2), R=4, D=100, r=as.numeric(factor(NC2$race)), d=as.numeric(factor(NC2$police_department)), n=NC2$n_stops, s=NC2$search_conducted, h=NC2$contraband_found)
# Compiling and producing posterior samples from the model.
stan_samples <- stan(file = "north_carolina_police.stan", data = data_list, chains = 2,iter = 200, control = list(adapt_delta = 0.99, max_treedepth=20))
# Compiling and producing posterior samples from the model.
stan_samples <- stan(file = "north_carolina_police.stan", data = data_list, chains = 2,iter = 200, control = list(adapt_delta = 0.99, max_treedepth=20))
# Compiling and producing posterior samples from the model.
stan_samples <- stan(file = "north_carolina_police.stan", data = data_list, chains = 2,iter = 200, control = list(adapt_delta = 0.8, max_treedepth=10))
# Compiling and producing posterior samples from the model.
stan_samples <- stan(file = "north_carolina_police.stan", data = data_list, chains = 2,iter = 500, control = list(adapt_delta = 0.9, max_treedepth=10))
rstan:::rstudio_stanc("C:/Users/luc/Desktop/GR5065/HW6/interval_regv2.stan")
sm <- rstan::stan_model("C:/Users/luc/Desktop/GR5065/HW6/interval_regv2.stan")
sm
rstan:::rstudio_stanc("C:/Users/luc/Desktop/GR5065/Final/cigarettes_rng.stan")
rstan:::rstudio_stanc("C:/Users/luc/Desktop/GR5065/Final/cigarettes_rng.stan")
rstan:::rstudio_stanc("C:/Users/luc/Desktop/GR5065/Final/cigarettes_rng.stan")
rstan:::rstudio_stanc("C:/Users/luc/Desktop/GR5065/Final/cigarettes_rng.stan")
load('C:/Users/luc/Desktop/awash/data/counties/waternet/waternet.RData')
a=nc_open('C:/Users/luc/Desktop/awash/data/cache/counties/VIC_WB.nc')
library(ncdf4)
a=nc_open('C:/Users/luc/Desktop/awash/data/cache/counties/VIC_WB.nc')
a$var
b=ncvar_get('month')
b=ncvar_get(a, 'month')
b
/
735/12
names(a$var)
a=nc_open('C:/Users/luc/Desktop/awash/data/cache/counties/contributing_runoff_by_gage.nc')
names(a$var)
b=ncvar_get(a, 'totalflow')
b
names(a$var)
ncvar_get(a, 'gage_id')
d=ncvar_get(a, 'gage_id')
d
load('C:/Users/luc/Desktop/awash/data/cache/counties/waternet/waternet.RData')
load('C:/Users/luc/Desktop/awash/data/counties/waternet/waternet.RData')
load('C:/Users/luc/Desktop/awash/data/counties/waternet/countydraws.RData')
load('C:/Users/luc/Desktop/Paleo/LBDA_sf/SF_disagg/results/monthly.disaggregation.Rdata')
load('C:/Users/luc/Desktop/Paleo/LBDA_sf/SF_disagg/results/CONUS/monthly.disaggregation.Rdata')
data=nc_open('C:/Users/luc/Desktop/awash/data/cache/paleo/VIC_WB.nc')
library(ncdf4)
data=nc_open('C:/Users/luc/Desktop/awash/data/cache/paleo/VIC_WB.nc')
names(data$var)
t=ncvar_get(data, 'month')
t
data=nc_open('C:/Users/luc/Desktop/awash/data/cache/counties/VIC_WB.nc')
names(data$var)
t=ncvar_get(data, 'month')
t
load("C:/Users/luc/Desktop/awash/data/counties/waternet/waternet.RData")
load('C:/Users/luc/Desktop/awash/data/counties/waternet/waternet.RData')
library(ncdf4)
nc_data=nc_open("C:/Users/luc/Desktop/awash/data/cache/counties/contributing_runoff_by_gage.nc")
names(nc_data$dim)
nc_data$dim
nc_data$gage
names(nc_data$dim)
nc_data$id
names(nc_data$var)
names(nc_data$dim)
load('C:/Users/luc/Desktop/awash/data/counties/waternet/waternet.RData')
load('C:/Users/luc/Desktop/awash/data/counties/waternet/waternet.RData')
library(ncdf4)
library(ggplot2)
library(ggmap)
library(broom)
library(maps)
library(maptools)
library(dplyr)
data(wrld_simpl)
################################################################################################################
##  Pre-process data and basic analysis
################################################################################################################
NOR=subset(wrld_simpl, NAME=="Norway")
setwd('C:/Users/luc/Desktop/CAI/proj1')
station_locations = read.csv("station_locations.csv")
station_locations$ids=c("Bruvolli", "Eidset", "Ekkjestolen", "Reingardsaga", "Stokkelandsana")
p <- ggplot()+
geom_polygon(data=tidy(NOR), aes(x=long, y=lat, group=group),colour="black", fill="white")+
geom_point(data=station_locations, aes(x=lon, y=lat))+
geom_text(data=station_locations,aes(x=lon, y=lat,label=station_id),hjust=0, vjust=0)+
theme_bw()
p
station_files = list.files()
station_files = station_files[grepl(".csv", station_files)]
station_files = station_files[!grepl("station_locations", station_files)]
Bruvolli = read.csv(station_files[1])
Eidset = read.csv(station_files[2])
Ekkjestolen = read.csv(station_files[3])
Reingardsaga = read.csv(station_files[4])
Stokkelandsana = read.csv(station_files[5])
Bruvolli$Flow[Bruvolli$Flow==-9999] <- NA
Eidset$Flow[Eidset$Flow==-9999] <- NA
Ekkjestolen$Flow[Ekkjestolen$Flow==-9999] <- NA
Reingardsaga$Flow[Reingardsaga$Flow==-9999] <- NA
Stokkelandsana$Flow[Stokkelandsana$Flow==-9999] <- NA
Bruvolli$Date=as.Date(Bruvolli$Date, format="%Y.%m.%d")
Eidset$Date=as.Date(Eidset$Date, format="%Y.%m.%d")
Ekkjestolen$Date=as.Date(Ekkjestolen$Date, format="%Y.%m.%d")
Reingardsaga$Date=as.Date(Reingardsaga$Date, format="%Y.%m.%d")
Stokkelandsana$Date=as.Date(Stokkelandsana$Date, format="%Y.%m.%d")
start=min(Bruvolli$Date, Eidset$Date, Ekkjestolen$Date, Reingardsaga$Date, Stokkelandsana$Date)
end=max(Bruvolli$Date, Eidset$Date, Ekkjestolen$Date, Reingardsaga$Date, Stokkelandsana$Date)
df=data.frame(Date=seq(start, end, by=1))
df$Stokkelandsana=df$Reingardsaga=df$Ekkjestolen=df$Eidset=df$Bruvolli=NA
df$Bruvolli[match(Bruvolli$Date,df$Date)]=Bruvolli$Flow
df$Eidset[match(Eidset$Date,df$Date)]=Eidset$Flow
df$Ekkjestolen[match(Ekkjestolen$Date,df$Date)]=Ekkjestolen$Flow
df$Reingardsaga[match(Reingardsaga$Date,df$Date)]=Reingardsaga$Flow
df$Stokkelandsana[match(Stokkelandsana$Date,df$Date)]=Stokkelandsana$Flow
cor(df[,2:6], use="pairwise.complete.obs")
pairs(df[,2:6])
acf(ts(df$Bruvolli[!is.na(df$Bruvolli)]))
acf(ts(df$Eidset[!is.na(df$Eidset)]))
acf(ts(df$Ekkjestolen[!is.na(df$Ekkjestolen)]))
acf(ts(df$Reingardsaga[!is.na(df$Reingardsaga)]))
acf(ts(df$Stokkelandsana[!is.na(df$Stokkelandsana)]))
plot(df$Bruvolli)
plot(df$Eidset)
plot(df$Ekkjestolen)
plot(df$Reingardsaga)
p
library(ncdf4)
nc_data=nc_open("C:/Users/luc/Desktop/awash/data/cache/counties/contributing_runoff_by_gage.nc")
library(ncdf4)
nc_data=nc_open("C:/Users/luc/Desktop/awash/data/cache/counties/contributing_runoff_by_gage.nc")
library(PBSmapping)
library(dplyr)
library(ggplot2)
library(ggmap)
library(maps)
library(maptools)
library(tmap)      # package for plotting
library(readxl)    # for reading Excel
library(tmaptools)
require(tidyr)
require(reshape2)
data(wrld_simpl)
wd_path = paste0("C:/Users/luc/Desktop/awash/analyses/climatevariability/")
setwd(wd_path)
# load
dem=read.csv("analyzereservoir_10yrs_12months/dem_tot.csv", header=F)
dem_p=read.csv("paleo_10yrs_12months/dem_tot.csv", header=F)
dem_diff=sum(unlist(dem), na.rm=T)-sum(unlist(dem_p), na.rm=T)
failurecon <- read.csv("analyzereservoir_10yrs_12months/failurecon.csv", header = F)
failurecon_p=read.csv("paleo_10yrs_12months/failurecon.csv", header=F)
failurecon_diff=sum(unlist(failurecon), na.rm=T)-sum(unlist(failurecon_p), na.rm=T)
failure=failurecon
per_cent_failure=100*failure/dem_tot
per_cent_failure[per_cent_failure==Inf]=0
p <- ggplot()+
geom_polygon(data=map, aes(x=long, y=lat, group = group),colour="black", fill="white")
# Set-up
start_year=2001
end_year=2010
tstep_py=1
nyears=end_year-start_year+1
time_ind0 <- 1:nyears*tstep_py
dir.create('plots', showWarnings=F)
# - county fips, state fips, region indexes
mastercounties <- read.csv("../../data/global/counties.csv")
fips <- matrix(mastercounties$fips, nrow = 3109, ncol = length(time_ind0)) %>% as.vector()
time_ind <- t(matrix(time_ind0, nrow = length(time_ind0), ncol = 3109)) %>% as.vector() %>% as.factor()
state_ind <- matrix(mastercounties$state, nrow = 3109, ncol = max(time_ind0)) %>% as.vector()
region_ind <- state_ind
region_ind[which(region_ind %in% c("CT", "ME", "MA", "NH", "RI", "VT"))] <- "I"
region_ind[which(region_ind %in% c("NJ", "NY"))] <- "II"
region_ind[which(region_ind %in% c("DE", "DC", "MD", "PA", "VA", "WV"))] <- "III"
region_ind[which(region_ind %in% c("AL", "FL", "GA", "KY", "MS", "NC", "SC", "TN"))] <- "IV"
region_ind[which(region_ind %in% c("IL", "IN", "MI", "MN", "OH", "WI"))] <- "V"
region_ind[which(region_ind %in% c("AR", "LA", "NM", "OK", "TX"))] <- "VI"
region_ind[which(region_ind %in% c("IA", "KS", "MO", "NE"))] <- "VII"
region_ind[which(region_ind %in% c("CO", "MT", "ND", "SD", "UT", "WY"))] <- "VIII"
region_ind[which(region_ind %in% c("AZ", "CA", "NV"))] <- "IX"
region_ind[which(region_ind %in% c("ID", "OR", "WA"))] <- "X"
fips <- mastercounties$fips
resdf <- read.csv("../../data/counties/reservoirs/allreservoirs.csv")
shapes <- importShapefile("C:/Users/luc/Desktop/awash/data/mapping/US_county_2000-simple")
polydata <- attributes(shapes)$PolyData
polydata$STATE <- as.numeric(levels(polydata$STATE))[polydata$STATE]
polydata$COUNTY <- as.numeric(levels(polydata$COUNTY))[polydata$COUNTY]
shapes$id <- polydata$STATE[shapes$PID] * 100 + polydata$COUNTY[shapes$PID] / 10;
names(shapes) <- tolower(names(shapes));
stateshapes <- importShapefile("../../data/mapping/tl_2010_us_state00/tl_2010_us_state00-simple")
statespolydata <- attributes(stateshapes)$PolyData
stateshapes$x <- stateshapes$X
stateshapes$y <- stateshapes$Y
stateshapes$id <- stateshapes$PID
failure_means=rowMeans(failurecon)
dem_sum=rowSums(dem)
dem_p_sum=rowSums(dem_p)
df <- data.frame(fips,dem_sum,dem_p_sum)
df$storage=NA
for (i in 1:nrow(df)){
df$storage[i]=sum(resdf$MAXCAP[which(resdf$fips==df$fips[i])])
}
df$ratio=df$dem_sum/df$storage
df$ratio_p=df$dem_p_sum/df$storage
library("RColorBrewer")
myPalette <- colorRampPalette(rev(brewer.pal(11, "Spectral")))
sc <- scale_colour_gradientn(colours = myPalette(100), limits=c(0, 3))
gplot1 <- ggplot() +
geom_map(data=stateshapes, map=stateshapes, aes(map_id=PID), color='gray', fill=NA) +
geom_map(data=df, aes(fill=ratio, map_id=fips), map=shapes) +
scale_fill_gradient(low="blue", high="red")+
expand_limits(x=c(-2500000, 2500000), y=c(-1.4e6, 1.6e6)) +
theme_bw() + theme(legend.justification=c(0,0), legend.position=c(0,0)) + xlab('') + ylab('')
gplot1
gplot2 <- ggplot() +
geom_map(data=stateshapes, map=stateshapes, aes(map_id=PID), color='gray', fill=NA) +
geom_map(data=df, aes(fill=ratio_p, map_id=fips), map=shapes) +
scale_fill_gradient(low="blue", high="red")+
expand_limits(x=c(-2500000, 2500000), y=c(-1.4e6, 1.6e6)) +
theme_bw() + theme(legend.justification=c(0,0), legend.position=c(0,0)) + xlab('') + ylab('')
gplot2
gplot1
gplot1 <- ggplot() +
geom_map(data=stateshapes, map=stateshapes, aes(map_id=PID), color='gray', fill=NA) +
geom_map(data=df, aes(fill=ratio, map_id=fips), map=shapes) +
scale_fill_gradient(low="blue", high="red")+
expand_limits(x=c(-2500000, 2500000), y=c(-1.4e6, 1.6e6)) +
theme_bw() + theme(legend.justification=c(0,0), legend.position=c(0,0)) + xlab('') + ylab('')+
ggtitle("Ratio of total demand over maximum storage capacity - comtemporary case")
gplot1
gplot2 <- ggplot() +
geom_map(data=stateshapes, map=stateshapes, aes(map_id=PID), color='gray', fill=NA) +
geom_map(data=df, aes(fill=ratio_p, map_id=fips), map=shapes) +
scale_fill_gradient(low="blue", high="red")+
expand_limits(x=c(-2500000, 2500000), y=c(-1.4e6, 1.6e6)) +
theme_bw() + theme(legend.justification=c(0,0), legend.position=c(0,0)) + xlab('') + ylab('')+
ggtitle("Ratio of total demand over maximum storage capacity - paleo case")
gplot2
gplot1
gplot2
## Parameters to change
result_path = paste0("C:/Users/luc/Desktop/awash/analyses/climatevariability/", "paper3/")
nlocs=3109
start_year=1451
end_year=2000
ttperyy=1
vrights=c("norightconst")
voptim <- c("surface")
namescenario <- paste0(vreval, "-",vrights)
vreval <- c("zero")
flowprop <- c("0.5")
simyrs=50
periods=seq(start_year, end_year, by=simyrs)
ee=1
nperiods=length(periods)
library(RColorBrewer)
## Load libraries and finish set-up
library(PBSmapping)
vreval <- c("zero")
namescenario <- paste0(vreval, "-",vrights)
flowprop <- c("0.5")
simyrs=50
periods=seq(start_year, end_year, by=simyrs)
nperiods=length(periods)
ee=1
## Load libraries and finish set-up
library(PBSmapping)
library(RColorBrewer)
library(dplyr)
library(ggplot2)
library(ggmap)
library(maps)
library(maptools)
library(tmap)      # package for plotting
library(readxl)    # for reading Excel
library(tmaptools)
library(reshape)
data(wrld_simpl)
source("../plotting.R")
setwd(result_path)
yearstot=end_year-start_year+1
setwd(result_path)
source("../plotting1.R")
stateshapes <- importShapefile("../../../data/mapping/tl_2010_us_state00/tl_2010_us_state00-simple")
source("../plotting1.R")
yearstot=end_year-start_year+1
ismultiyr=0
if (yearstot>1) {ismultiyr=1}
time_ind0 <- 1:(yearstot*ttperyy)
dir.create('plots', showWarnings=F)
source("../readAWASHresults.R")
mc <- read.csv("../../../data/global/counties.csv")
source("../readAWASHresults1.R")
source("../readAWASHresults1.R")
tokm3 <- T
if(tokm3){
result <- result *1e-6
unitvol <- "[km3/yr]"
}else{unitvol <- "[1000m3/yr]"}
result_files=list.files()
result_files
result_files=list.files("paleo_1451-2000")
result_files
result=array(dim=c(nlocs, simyrs*ttperyy, nperiods))
for(k in 1:nperiods){
result[,,k]=as.matrix(read.csv(result_files[k], header=F))
}
for(k in 1:nperiods){
result[,,k]=as.matrix(read.csv(paste0("paleo_1451-2000/",result_files[k]), header=F))
}
names(result)=c("fips", "year", "period", "failures")
dfbx=as.data.frame(apply(result, MARGIN=c(2,3), FUN=sum))
colnames(dfbx)=paste0(start_years, "-", end_years)
dfbx=melt(dfbx)
View(dfbx)
paste0(start_years, "-", end_years)
start_years
start_years=seq(start_year, end_year-simyrs+1, by=simyrs)
end_years=seq(start_year+simyrs-1, end_year, by=simyrs)
colnames(dfbx)=paste0(start_years, "-", end_years)
dfbx=melt(dfbx)
colnames(dfbx)=c("Period", "Failures")
h <- ggplot(data=dfbx, aes(x=Period, y=Failures))+geom_boxplot()
+
ggtitle("Boxplots of failures per period of 50 years")+
xlab("Period")+
ylab("Failures ([1000 m3]")+
theme_bw()
h <- ggplot(data=dfbx, aes(x=Period, y=Failures))+geom_boxplot()+
ggtitle("Boxplots of failures per period of 50 years")+
xlab("Period")+
ylab("Failures ([1000 m3]")+
theme_bw()
print(h)
dfbx$Time=time_ind0+start_year
h <- ggplot(data=dfbx, aes(x=Time, y=Failures))+
geom_line(color="#CC79A7", size=1)+
ggtitle("Time series of failures (runs per period of 50 years)")+
xlab("Time")+
ylab("Failures ([1000 m3]")+
theme_bw()
print(h)
df_counties=read.csv(paste0("counties/failure-surface-propenv0.5-rescapzero-norightconst-1950.csv"), header=F)
View(dfbx)
result_counties=read.csv(paste0("counties/failure-surface-propenv0.5-rescapzero-norightconst-1950.csv"), header=F)
df_counties2=as.data.frame(apply(result_counties, MARGIN=2, FUN=sum))
View(df_counties2)
df_counties2$Time=c(1950:2005)
View(df_counties2)
result_counties=read.csv(paste0("counties/failure-surface-propenv0.5-rescapzero-norightconst-1950.csv"), header=F)
df_counties2=as.data.frame(Failures=apply(result_counties, MARGIN=2, FUN=sum))
df_counties2=data.frame(Failures=apply(result_counties, MARGIN=2, FUN=sum))
df_counties2$Time=c(1950:2005)
View(df_counties2)
h <- ggplot()+
geom_line(data=dfbx, aes(x=Time, y=Failures),color="#CC79A7", size=1)+
geom_line(data=df_counties2, aes(x=Time, y=Failures),color="green", size=1)+
ggtitle("Time series of failures (runs per period of 50 years)")+
xlab("Time")+
ylab("Failures ([1000 m3]")+
theme_bw()
h
max(df_counties2$Failures)
h <- ggplot()+
#geom_line(data=dfbx, aes(x=Time, y=Failures),color="#CC79A7", size=1)+
geom_line(data=df_counties2, aes(x=Time, y=Failures),color="green", size=1)+
ggtitle("Time series of failures (runs per period of 50 years)")+
xlab("Time")+
ylab("Failures ([1000 m3]")+
theme_bw()
h
a=read.csv(paste0("counties/failure-surface-propenv0.5-rescapzero-norightconst-1950.csv"), header=F)
aa=read.csv(paste0("paleo_1451-2000/failure-surface-propenv0.5-rescapzero-norightconst-1451.csv"), header=F)
max(a)
max(aa)
max(aa)/max(a)
b=apply(a, MARGIN=2, FUN=sum)
bb=apply(aa, MARGIN=2, FUN=sum)
max(bb)/max(b)
mean(bb)/mean(b)
aaa=read.csv(paste0("analyzereservoir_10yrs_12months/failuresin.csv"), header=F)
aaa=read.csv(paste0("../analyzereservoir_10yrs_12months/failuresin.csv"), header=F)
bbb=apply(aaa, MARGIN=2, FUN=sum)
mean(bbb)/mean(b)
a=read.csv(paste0("counties/failure-surface-propenv0.5-rescapzero-norightconst-1950old.csv"), header=F)
aa=read.csv(paste0("counties/failure-surface-propenv0.5-rescapzero-norightconst-1950.csv"), header=F)
aa=read.csv(paste0("counties/failure-surface-propenv0.5-rescapzero-norightconst-yearly-1950.csv"), header=F)
max(abs(a[,1:51]-aa))
a0=read.csv(paste0("counties/failure-surface-propenv0.5-rescapzero-norightconst-1950.csv"), header=F)
a1=read.csv(paste0("paleo_1451-2000/failure-surface-propenv0.5-rescapzero-norightconst-1451.csv"), header=F)
a2=read.csv(paste0("../analyzereservoir_10yrs_12months/failuresin.csv"), header=F)
a3=read.csv(paste0("counties/failure-surface-propenv0.5-rescapzero-norightconst-yearly-1950.csv"), header=F)
b0=apply(a0, MARGIN=2, FUN=sum)
b1=apply(a1, MARGIN=2, FUN=sum)
b2=apply(a2, MARGIN=2, FUN=sum)
b3=apply(a3, MARGIN=2, FUN=sum)
a0=read.csv(paste0("counties/failure-surface-propenv0.5-rescapzero-norightconst-1950.csv"), header=F)
a0=read.csv(paste0("counties/failure-surface-propenv0.5-rescapzero-norightconst-1950old.csv"), header=F)
a1=read.csv(paste0("paleo_1451-2000/failure-surface-propenv0.5-rescapzero-norightconst-1451.csv"), header=F)
a2=read.csv(paste0("../analyzereservoir_10yrs_12months/failuresin.csv"), header=F)
a3=read.csv(paste0("counties/failure-surface-propenv0.5-rescapzero-norightconst-yearly-1950.csv"), header=F)
b0=apply(a0, MARGIN=2, FUN=sum)
b1=apply(a1, MARGIN=2, FUN=sum)
b2=apply(a2, MARGIN=2, FUN=sum)
b3=apply(a3, MARGIN=2, FUN=sum)
mean(b0)/mean(b1)
mean(b0)/mean(b3)
mean(b1)/mean(b0)
mean(b3)/mean(b0)
